{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f31e450",
   "metadata": {},
   "source": [
    "## Model evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd85800",
   "metadata": {},
   "source": [
    "In this notebook, we load and estimate the images. To estimate, we use trained models from the DivBlurring_training.ipynb file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f31e450",
   "metadata": {},
   "source": [
    "## Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05894b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tifffile import imread\n",
    "from glob import glob\n",
    "from tifffile import imsave\n",
    "from IPython.display import clear_output\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645bcf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log10, sqrt\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\") \n",
    "print(device)\n",
    "from Network import network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69f0f87",
   "metadata": {},
   "source": [
    "## Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe144b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8 # the data which is not used to train the model.\n",
    "noisy_input= imread(\"./data/data4Sai/\"+'BluryNoisy_tubulins_'+str(i)+'_SOFImodel.tif')\n",
    "signal= imread(\"./data/data4Sai/\"+'tubulins_'+str(i)+'_SOFImodel.tif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dee811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(original, compressed):\n",
    "    \"\"\"Code snippet to calculate the PSNR value for the 100 samples.\n",
    "    \"\"\"\n",
    "    mse = np.mean((original - compressed) ** 2)\n",
    "    if(mse == 0):\n",
    "     return 100\n",
    "    max_pixel = np.max(original)\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
    "    #  print(psnr)\n",
    "    return psnr \n",
    " \n",
    "def predict_mmse(vae, img, samples, device, returnSamples=False, tq=True): \n",
    "    '''\n",
    "    Predicts MMSE estimate.\n",
    "    Parameters\n",
    "\n",
    "    '''\n",
    "    img_height,img_width=img.shape[0],img.shape[1]\n",
    "    imgT=torch.Tensor(img.copy())\n",
    "    image_sample = imgT.view(1,1,img_height,img_width).to(device)\n",
    "    vae.num_samples = samples\n",
    "    all_samples = np.array(vae(image_sample,tqdm_bar=tq))\n",
    "    samples_array = all_samples[:,0,0,:,:]\n",
    "    if returnSamples:\n",
    "        return np.mean(samples_array,axis=0), samples_array\n",
    "    else:\n",
    "        return np.mean(samples_array,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b936ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_models(VAELightning,basedir,model_name,noisy_input,signal,method):\n",
    "    \"\"\"THe method to estimate and calculate the mean of PSNR for 100 estimates.\n",
    "    \"\"\"\n",
    "    name = glob(basedir+\"/\"+model_name+'_last.ckpt')[0]\n",
    "    vae = VAELightning.load_from_checkpoint(checkpoint_path = name)\n",
    "    if not torch.cuda.is_available():\n",
    "        raise ValueError(\"GPU not found, predictions will run on CPU and can be somewhat slow!\")\n",
    "    else:\n",
    "        vae.to(device)\n",
    "    \n",
    "    imgMMSE, samps = predict_mmse(vae, noisy_input[0], samples=100, device=device, returnSamples=True)\n",
    "    for i in range(1):\n",
    "        plt.figure(figsize = (20,4))\n",
    "        plt.title(label=method)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(imgMMSE)\n",
    "        plt.clim(vmin = np.min(signal[0]), vmax =np.max(signal[0])*(0.4))\n",
    "        plt.show()\n",
    "    psnr= []\n",
    "    for i in range(100):\n",
    "        imgMMSE, samps = predict_mmse(vae, noisy_input[i], samples=100, device=device, returnSamples=True)\n",
    "        psnr_i = PSNR(signal[i],imgMMSE)\n",
    "        psnr.append(psnr_i)\n",
    "\n",
    "    print(\"The mean value of PSNR 100 predictions for \"+ method +\":\"+str(np.mean(psnr)))\n",
    "    print(\"Min value of predicted img:\"+str(np.min(imgMMSE)))\n",
    "    print(\"Max value of predicted img:\"+str(np.max(imgMMSE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21134bf",
   "metadata": {},
   "source": [
    "## True Signal and Noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c68e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The true signal and noisy data.\n",
    "\n",
    "plt.figure(figsize = (60,8))\n",
    "plt.subplot(211)\n",
    "plt.title(label='True signal img')\n",
    "plt.axis('off')\n",
    "plt.imshow(signal[i])\n",
    "plt.clim(vmin = np.min(signal[0]), vmax =np.max(signal[0])*(0.4))\n",
    "plt.subplot(212)\n",
    "plt.title(label='Observed Noisy img')\n",
    "plt.axis('off')\n",
    "plt.imshow(noisy_input[i])\n",
    "plt.clim(vmin = np.min(signal[0]), vmax =np.max(signal[0])*(0.4))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f340922d",
   "metadata": {},
   "source": [
    "## Ploting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90981e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_input = noisy_input\n",
    "signal= signal\n",
    "method = ['DivBlurring','DivBlurring_l1','DivBlurring_l2',\n",
    "                    'DivBlurring_PCReg_1e3','DivBlurring_PCReg_1e5',\n",
    "                    'DivBlurring_PCReg_l1'] # Definced approches.\n",
    "model_name = ['models_DivBlurring','models_DivBlurring_l1Regu_1e10','models_DivBlurring_l2Regu_1e10',\n",
    "                    'models_DivBlurring_PCReg_1e3','models_DivBlurring_PCReg_1e5',\n",
    "                    'models_DivBlurring_PC_l1X_Reg_1e3_1e10'] # a name used to identify the model.\n",
    "basedir = model_name # the base directory in which our model will be saved, we prefer same directory as model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6040e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(method)):\n",
    "    estimate_models(network.VAELightning,basedir[i],model_name[i],noisy_input,signal,method[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a3b39f",
   "metadata": {},
   "source": [
    "## Loss values comparision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d46ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from matplotlib.pyplot import axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd049223",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = {} \n",
    "for i in model_name:\n",
    "    ea = event_accumulator.EventAccumulator(i, size_guidance={event_accumulator.SCALARS: 0})\n",
    "    ea.Reload()\n",
    "    dframes = DataFrame()\n",
    "    dframes_total = DataFrame()\n",
    "    mnames = ['reconstruction_loss_epoch', 'kl_loss_epoch', 'training_loss_epoch']\n",
    "\n",
    "\n",
    "    for n in mnames:\n",
    "        dframes = pd.DataFrame(ea.Scalars(n), columns=[\"wall_time\", \"epoch\", n.replace('val/', '')])      \n",
    "        dframes = dframes.drop(columns=['epoch','wall_time'])\n",
    "        dframes_total[n] = dframes[n]\n",
    "        dframes = DataFrame()\n",
    "    \n",
    "    all_dfs[i] = dframes_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1123fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in mnames:\n",
    "    for i in model_name:\n",
    "        plt.plot(all_dfs[i][j], label = i)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title(j+' Loss values')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a48566917f2d7885bc685087ba06e234e51f695c26e8557391e1a3095fa44fa0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
