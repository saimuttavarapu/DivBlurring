{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5630fc53",
   "metadata": {},
   "source": [
    "# Training the BivBlurring model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674becbc",
   "metadata": {},
   "source": [
    "In this notebook we train the DivBlurring model. Our approach “DivBlurring” is an \"inverse image reconstruction model\" reconstructing biomedical images from an inverse problem perspective. For the training, we are using the PyTorch_Lighiting framefwork on synthatic data. This data generated based on the realistic data.\n",
    "The task is reconstructing the desired image from the noisy and blurry data by using generative approaches such as variational auto encoder in combination with the use of a physical model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f31e450",
   "metadata": {},
   "source": [
    "## Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db96a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import os\n",
    "from torch.distributions import normal\n",
    "import matplotlib.pyplot as plt, numpy as np, pickle\n",
    "from tifffile import imread\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05894b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import pytorch_lightning as pl\n",
    "import logging\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645bcf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\") \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c10f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utilities\n",
    "import loss_function\n",
    "from Network import network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69f0f87",
   "metadata": {},
   "source": [
    "## Download and split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba01fa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the data is avialable in the data folder.\n",
    "\n",
    "datai = []\n",
    "observation= []\n",
    "for i in range(1): # As data in multiple files, looping over the all files.\n",
    "    datai= imread(\"./data/data4Sai/\"+'BluryNoisy_tubulins_'+str(i+1)+'_SOFImodel.tif')\n",
    "    observation.extend(datai)\n",
    "observation = np.array(observation)\n",
    "\n",
    "print(observation.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b806d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data and shape of the total data set.\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title(label='Single raw Image')\n",
    "plt.imshow(observation[0],cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"Total number imgs in the give dataset:\" + str(observation.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6252104",
   "metadata": {},
   "source": [
    "Spli the data 85% for the thraining and 15% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4133f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, val_images = utilities.get_split_data(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab427739",
   "metadata": {},
   "source": [
    "## Convert data to tensor for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd902d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor, x_val_tensor, data_mean, data_std = utilities.preprocess(train_images, val_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126ccf46",
   "metadata": {},
   "source": [
    "## Required params for trianing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad111ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_depth=2 #number of layers for the network.\n",
    "batch_size=32 #batch size.\n",
    "max_epochs=1 #Total numebr of epochs for trianing.\n",
    "real_noise=False # Predifined noise.\n",
    "noise_model = None #Predefined noise model.\n",
    "gaussian_noise_std = 10 # The considered noise level for known case.\n",
    "sigma = 3 #Blur level in FWHM in nanometers\n",
    "shape = 256 #Shape of the input image.\n",
    "img_per_each_epochs = [] #To same the img at some iteration for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3e3d9e",
   "metadata": {},
   "source": [
    "## Convolution generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d217e4a9",
   "metadata": {},
   "source": [
    "The below cells gnerate the blur kernal, then that is transformed into frequency domain with the help of fast furio transform(fft). In the loss function the predicted image also transformed into frequency domain, after that we multiplied both blur kernal and image which are in frequency domain. Later we transformed back into image domin with inverse fast furio transform(ifft)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f8b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(sigma, shape):\n",
    "        \"\"\"Generating blur kernal for the convultion.\n",
    "        \"\"\"\n",
    "        sigma = sigma\n",
    "        n = shape\n",
    "        t = np.concatenate( (np.arange(0,n/2+1), np.arange(-n/2,-1)) )\n",
    "        [Y,X] = np.meshgrid(t,t)\n",
    "        h = np.exp( -(X**2+Y**2)/(2.0*float(sigma)**2) )\n",
    "        h = h/np.sum(h)\n",
    "        hf = np.real(np.fft.fft2(h))\n",
    "        # hf = torch.from_numpy(hf).to(device='cuda') \n",
    "        return hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f940b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = convolution(sigma, shape) # Generating psf in frequency domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df460cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to check effectivly for posterior collapse.\n",
    "\n",
    "def train_network(x_train_tensor, x_val_tensor, batch_size, data_mean, data_std, gaussian_noise_std, \n",
    "                  noise_model, hf, reg_parameter, method, n_depth, max_epochs, model_name, basedir, log_info=False):\n",
    "    \"\"\"\"To train the model along wiht added check points for tensorflow observation.\n",
    "    \"\"\"\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(\"The method: \"+str(method))\n",
    "    print(\"Regularisation parameter: \"+str(reg_parameter))\n",
    "    print(\"---------------------------------------------\")\n",
    "    train_loader,val_loader = utilities.create_dataloaders(x_train_tensor, x_val_tensor, batch_size)\n",
    "    collapse_flag = True\n",
    "    if not os.path.exists(basedir):\n",
    "        os.makedirs(basedir)\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath=basedir,\n",
    "    filename=model_name+'_best',\n",
    "    save_last=True,\n",
    "    save_top_k=1,\n",
    "    mode='min',)\n",
    "    checkpoint_callback.CHECKPOINT_NAME_LAST = model_name+\"_last\"\n",
    "    logger = TensorBoardLogger(basedir, name= \"\", version=\"\", default_hp_metric=False)\n",
    "    weights_summary=\"full\" #if log_info else None\n",
    "    if not log_info:\n",
    "        pl.utilities.distributed.log.setLevel(logging.ERROR)\n",
    "    posterior_collapse_count = 0\n",
    "    \n",
    "    #Check posterior collapse for 20 times.\n",
    "    while collapse_flag and posterior_collapse_count<20:\n",
    "        collapse_flag, vae = utilities.create_model_and_train(basedir,data_mean,data_std,gaussian_noise_std,noise_model, hf,reg_parameter,method,\n",
    "                                               n_depth,max_epochs,logger,checkpoint_callback,\n",
    "                                               train_loader,val_loader,kl_annealing=False, weights_summary=weights_summary)\n",
    "        if collapse_flag:\n",
    "            posterior_collapse_count=posterior_collapse_count+1\n",
    "        \n",
    "    if collapse_flag:\n",
    "        print(\"Posterior collapse limit reached, attempting training with KL annealing turned on!\")\n",
    "        while collapse_flag:\n",
    "            collapse_flag, vae = utilities.create_model_and_train(basedir,data_mean,data_std,gaussian_noise_std,noise_model, hf,reg_parameter,method,\n",
    "                                               n_depth,max_epochs,logger,checkpoint_callback,\n",
    "                                               train_loader,val_loader,kl_annealing=True, weights_summary=weights_summary)\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc4a194",
   "metadata": {},
   "source": [
    "## Train the DivBlurring model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e05a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = ['DivBlurring','DivBlurring_l1','DivBlurring_l2',\n",
    "                    'DivBlurring_PCReg_1e3','DivBlurring_PCReg_1e5',\n",
    "                    'DivBlurring_PCReg_l1'] # Definced approches.\n",
    "model_name = ['models_DivBlurring','models_DivBlurring_l1Regu_1e10','models_DivBlurring_l2Regu_1e10',\n",
    "                    'models_DivBlurring_PCReg_1e3','models_DivBlurring_PCReg_1e5',\n",
    "                    'models_DivBlurring_PC_l1X_Reg_1e3_1e10'] # a name used to identify the model.\n",
    "basedir = model_name # the base directory in which our model will be saved, we prefer same directory as model name.\n",
    "reg_parameter = [0, 1e-10, 1e-10, 1e-3, 1e-5, [1e-3,1e-10]] # Regularisation parameters with respec to the methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73a2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training all methods with predifined regularier parameters.\n",
    "\n",
    "for i in range(len(method)):\n",
    "    vae = train_network(x_train_tensor, x_val_tensor, batch_size, data_mean, data_std, \n",
    "                       gaussian_noise_std, noise_model, hf = hf, reg_parameter=reg_parameter[i], method=method[i], n_depth=n_depth, max_epochs=max_epochs, \n",
    "                       model_name=model_name[i], basedir=basedir[i], log_info=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bce57f",
   "metadata": {},
   "source": [
    "## Trained models will be saved after successful trianing respect to basedir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b130dbf7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('DivBlurring': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f8a32e362d240c1f3801891b46d8ec648b0531649b7e8492333702ab98988df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
